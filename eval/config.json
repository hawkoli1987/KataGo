{
  "_comment": "Sample configurations for eval.py. Copy and modify as needed.",
  
  "examples": {
    "openai_vllm": {
      "candidate": {
        "type": "openai",
        "api_base": "http://localhost:8002/v1",
        "model": null,
        "api_key": null,
        "temperature": 0.1,
        "max_tokens": 1024
      },
      "evaluation": {
        "model_name": "qwen3-vl-eval",
        "games_per_level": 48,
        "promotion_threshold": 0.55,
        "starting_elo": 1000
      }
    },
    
    "huggingface": {
      "candidate": {
        "type": "huggingface",
        "model_path": "/path/to/checkpoint",
        "device": "cuda",
        "temperature": 0.1,
        "max_new_tokens": 1024
      },
      "evaluation": {
        "model_name": "my-hf-model-eval",
        "games_per_level": 48,
        "promotion_threshold": 0.55,
        "starting_elo": 1000
      }
    },
    
    "katago": {
      "candidate": {
        "type": "katago",
        "model_path": "assets/models/level_02_kata1-b10c128-s197428736-d67404019.txt.gz"
      },
      "evaluation": {
        "model_name": "katago-level2-eval",
        "games_per_level": 48,
        "promotion_threshold": 0.55,
        "starting_elo": 1000
      }
    }
  },
  
  "defaults": {
    "katago_path": "/scratch/Projects/SPEC-SF-AISG/katago/bin/katago-cuda/katago",
    "katago_config": "/scratch/Projects/SPEC-SF-AISG/katago/bin/katago-cuda/default_gtp.cfg",
    "manifest_path": "assets/models/manifest.json",
    "output_dir": "data/eval"
  }
}
